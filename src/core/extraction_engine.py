"""Three-Tier Extraction System - hierarchical data extraction with fallback mechanism.

Core Architecture:
1. Layer 1 (Priority): Network Sniffing - intercepts raw API JSON responses
2. Layer 2 (Self-healing): Heuristic XPath - visual feature-based element location
3. Layer 3 (Fallback): Intelligent Mock - generates data matching trends

Design Principles:
- Never fail: Each layer has the next as fallback mechanism
- Data integrity: Source marks indicate extraction method (api/html/mock)
- Traceability: Tracks fallback path for optimization insights
"""
import json
import random
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from loguru import logger


class ExtractionEngine:
    """ä¸‰å±‚é™çº§æŠ“å–å¼•æ“"""
    
    def __init__(self):
        self.extraction_stats = {
            'api': 0,
            'html': 0,
            'mock': 0
        }
    
    async def extract_with_fallback(
        self,
        api_extractor: Optional[callable] = None,
        html_extractor: Optional[callable] = None,
        mock_generator: Optional[callable] = None,
        context: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        ä¸‰å±‚é™çº§æŠ“å–ä¸»å…¥å£
        
        Args:
            api_extractor: API å—…æ¢æå–å‡½æ•°
            html_extractor: HTML å¯å‘å¼æå–å‡½æ•°
            mock_generator: Mock æ•°æ®ç”Ÿæˆå‡½æ•°
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå…³é”®è¯ã€é¡µæ•°ç­‰ï¼‰
        
        Returns:
            æå–çš„æ•°æ®åˆ—è¡¨ï¼ˆå¸¦æ¥æºæ ‡è®°ï¼‰
        """
        context = context or {}
        
        # ç¬¬ä¸€å±‚ï¼šNetwork Sniffingï¼ˆä¼˜å…ˆï¼‰
        if api_extractor:
            logger.info("ğŸ§ [Layer 1] å°è¯• Network Sniffing...")
            try:
                api_data = await api_extractor()
                if api_data and len(api_data) > 0:
                    self.extraction_stats['api'] += len(api_data)
                    logger.success(f"âœ… [Layer 1] Network Sniffing æˆåŠŸï¼è·å– {len(api_data)} æ¡çº¯å‡€æ•°æ®")
                    return self._mark_source(api_data, 'api')
            except Exception as e:
                logger.warning(f"âš ï¸ [Layer 1] Network Sniffing å¤±è´¥: {e}")
        
        # ç¬¬äºŒå±‚ï¼šå¯å‘å¼ XPathï¼ˆè‡ªæ„ˆï¼‰
        if html_extractor:
            logger.info("ğŸ” [Layer 2] å¯åŠ¨å¯å‘å¼ XPath æå–...")
            try:
                html_data = await html_extractor()
                if html_data and len(html_data) > 0:
                    self.extraction_stats['html'] += len(html_data)
                    logger.success(f"âœ… [Layer 2] å¯å‘å¼æå–æˆåŠŸï¼è·å– {len(html_data)} æ¡æ•°æ®")
                    return self._mark_source(html_data, 'html')
            except Exception as e:
                logger.warning(f"âš ï¸ [Layer 2] å¯å‘å¼æå–å¤±è´¥: {e}")
        
        # ç¬¬ä¸‰å±‚ï¼šæ™ºèƒ½ Mockï¼ˆä¿åº•ï¼‰
        if mock_generator:
            logger.warning("ğŸ­ [Layer 3] å¯åŠ¨æ™ºèƒ½ Mock ä¿åº•æœºåˆ¶...")
            try:
                mock_data = await mock_generator(context)
                if mock_data:
                    self.extraction_stats['mock'] += len(mock_data)
                    logger.info(f"ğŸ­ [Layer 3] Mock æ•°æ®ç”ŸæˆæˆåŠŸï¼ç”Ÿæˆ {len(mock_data)} æ¡æ¨¡æ‹Ÿæ•°æ®")
                    return self._mark_source(mock_data, 'mock')
            except Exception as e:
                logger.error(f"âŒ [Layer 3] Mock ç”Ÿæˆå¤±è´¥: {e}")
        
        logger.error("âŒ ä¸‰å±‚é™çº§å…¨éƒ¨å¤±è´¥ï¼è¿”å›ç©ºæ•°æ®")
        return []
    
    def _mark_source(self, data: List[Dict], source: str) -> List[Dict]:
        """æ ‡è®°æ•°æ®æ¥æº"""
        for item in data:
            item['_extraction_source'] = source
            item['_extraction_time'] = datetime.now().isoformat()
        return data
    
    def get_stats(self) -> Dict[str, int]:
        """è·å–æå–ç»Ÿè®¡"""
        total = sum(self.extraction_stats.values())
        if total == 0:
            return self.extraction_stats
        
        stats_with_percent = {
            'api': {'count': self.extraction_stats['api'], 
                   'percent': f"{self.extraction_stats['api']/total*100:.1f}%"},
            'html': {'count': self.extraction_stats['html'], 
                    'percent': f"{self.extraction_stats['html']/total*100:.1f}%"},
            'mock': {'count': self.extraction_stats['mock'], 
                    'percent': f"{self.extraction_stats['mock']/total*100:.1f}%"},
            'total': total
        }
        return stats_with_percent


class HeuristicExtractor:
    """å¯å‘å¼æå–å™¨ï¼ˆåŸºäºè§†è§‰ç‰¹å¾ï¼‰"""
    
    @staticmethod
    async def extract_by_visual_features(page, platform: str = 'xiaohongshu') -> List[Dict]:
        """
        åŸºäºè§†è§‰ç‰¹å¾æå–æ•°æ®ï¼ˆç¬¬äºŒå±‚ï¼‰
        
        æ ¸å¿ƒæ€æƒ³ï¼š
        - ä¸ä¾èµ– CSS ç±»åï¼ˆæ˜“å˜ï¼‰
        - ä½¿ç”¨è§†è§‰ç‰¹å¾ï¼šå›¾æ ‡ã€å¸ƒå±€ã€æ–‡æœ¬æ¨¡å¼
        - XPath + è¯­ä¹‰åŒ–å®šä½
        
        Args:
            page: Playwright Page å¯¹è±¡
            platform: å¹³å°åç§°
        
        Returns:
            æå–çš„æ•°æ®åˆ—è¡¨
        """
        if platform == 'xiaohongshu':
            return await HeuristicExtractor._extract_xiaohongshu_by_visual(page)
        else:
            logger.warning(f"æœªæ”¯æŒçš„å¹³å°: {platform}")
            return []
    
    @staticmethod
    async def _extract_xiaohongshu_by_visual(page) -> List[Dict]:
        """
        å°çº¢ä¹¦è§†è§‰ç‰¹å¾æå–ï¼ˆå¯å‘å¼ï¼‰
        
        ç‰¹å¾è¯†åˆ«ï¼š
        1. ç¬”è®°å¡ç‰‡ï¼šåŒ…å«å›¾ç‰‡ + æ ‡é¢˜ + ä½œè€…
        2. ç‚¹èµå›¾æ ‡ï¼šâ¤ï¸ æˆ– like-icon
        3. äº’åŠ¨å®¹å™¨ï¼šå›ºå®šå¸ƒå±€ä½ç½®
        """
        notes = []
        
        # ç­–ç•¥1: é€šè¿‡å›¾ç‰‡å®¹å™¨æŸ¥æ‰¾ç¬”è®°å¡ç‰‡
        visual_xpath = """
        //section[.//img and .//a[@title]]
        | //div[contains(@class, 'note') or contains(@class, 'card')][.//img]
        | //article[.//img and .//h3]
        """
        
        try:
            cards = await page.locator(visual_xpath).all()
            logger.info(f"ğŸ” è§†è§‰ç‰¹å¾å®šä½åˆ° {len(cards)} ä¸ªç¬”è®°å®¹å™¨")
            
            for idx, card in enumerate(cards):
                try:
                    # æå–æ ‡é¢˜ï¼ˆä¼˜å…ˆçº§ï¼šh3 > h2 > a[@title] > strongï¼‰
                    title = ""
                    for title_xpath in ['.//h3', './/h2', './/a[@title]', './/strong']:
                        try:
                            title_elem = card.locator(title_xpath).first
                            title_text = await title_elem.text_content()
                            if title_text and len(title_text) > 3:
                                title = title_text.strip()
                                break
                        except:
                            continue
                    
                    # æå–å›¾ç‰‡é“¾æ¥
                    image_url = ""
                    try:
                        img = card.locator('img').first
                        image_url = await img.get_attribute('src')
                    except:
                        pass
                    
                    # æå–ç‚¹èµæ•°ï¼ˆæŸ¥æ‰¾â¤ï¸å›¾æ ‡é™„è¿‘çš„æ•°å­—ï¼‰
                    likes = 0
                    try:
                        # ç­–ç•¥ï¼šæŸ¥æ‰¾åŒ…å«æ•°å­—ä¸”é è¿‘ like/heart å›¾æ ‡çš„å…ƒç´ 
                        like_xpath = './/*[contains(@class, "like") or contains(@class, "heart")]/..//*[contains(text(), "")]'
                        like_text = await card.locator(like_xpath).first.text_content()
                        likes = HeuristicExtractor._parse_interaction_count(like_text)
                    except:
                        pass
                    
                    if title:  # è‡³å°‘æœ‰æ ‡é¢˜æ‰è®¤ä¸ºæ˜¯æœ‰æ•ˆæ•°æ®
                        notes.append({
                            'title': title,
                            'image_url': image_url,
                            'likes': likes,
                            'author': '',  # å¾…æå–
                            'platform': 'xiaohongshu'
                        })
                        
                except Exception as e:
                    logger.debug(f"æå–ç¬”è®° {idx} å¤±è´¥: {e}")
                    continue
            
            return notes
            
        except Exception as e:
            logger.error(f"è§†è§‰ç‰¹å¾æå–å¤±è´¥: {e}")
            return []
    
    @staticmethod
    def _parse_interaction_count(text: str) -> int:
        """è§£æäº’åŠ¨æ•°ï¼ˆæ”¯æŒ 1.2wã€5k ç­‰æ ¼å¼ï¼‰"""
        if not text:
            return 0
        
        import re
        # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼Œä¿ç•™ w/k/ä¸‡/åƒ
        text = text.lower().strip()
        
        # åŒ¹é…æ¨¡å¼ï¼š123ã€1.2wã€5k
        match = re.search(r'([\d.]+)([wkä¸‡åƒ]?)', text)
        if not match:
            return 0
        
        num_str, unit = match.groups()
        try:
            num = float(num_str)
            if unit in ['w', 'ä¸‡']:
                return int(num * 10000)
            elif unit in ['k', 'åƒ']:
                return int(num * 1000)
            else:
                return int(num)
        except:
            return 0


class SmartMockGenerator:
    """æ™ºèƒ½ Mock æ•°æ®ç”Ÿæˆå™¨ï¼ˆç¬¬ä¸‰å±‚ä¿åº•ï¼‰"""
    
    @staticmethod
    async def generate_trending_data(context: Dict[str, Any]) -> List[Dict]:
        """
        ç”Ÿæˆç¬¦åˆè¶‹åŠ¿çš„æ¨¡æ‹Ÿæ•°æ®
        
        Args:
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
                - keyword: æœç´¢å…³é”®è¯
                - count: ç”Ÿæˆæ•°é‡
                - platform: å¹³å°åç§°
        
        Returns:
            æ¨¡æ‹Ÿæ•°æ®åˆ—è¡¨
        """
        keyword = context.get('keyword', 'é»˜è®¤è¯é¢˜')
        count = context.get('count', 10)
        platform = context.get('platform', 'xiaohongshu')
        
        logger.info(f"ğŸ­ ç”Ÿæˆ Mock æ•°æ®: {keyword} x {count} æ¡")
        
        mock_data = []
        
        # æ ‡é¢˜æ¨¡æ¿ï¼ˆç¬¦åˆå°çº¢ä¹¦é£æ ¼ï¼‰
        title_templates = [
            f"{keyword}ï½œè¿™ä¸ªæ–¹æ³•çœŸçš„æœ‰ç”¨ï¼",
            f"åˆ†äº«ä¸€ä¸ª{keyword}çš„å°æŠ€å·§",
            f"{keyword}é¿å‘æŒ‡å—ğŸ“",
            f"å…³äº{keyword}ï¼Œæˆ‘æƒ³è¯´...",
            f"{keyword}å…¥é—¨å¿…çœ‹ï¼",
            f"çœŸå®æµ‹è¯„ï½œ{keyword}",
            f"{keyword}å®è—åˆ†äº«âœ¨",
            f"è¶…è¯¦ç»†{keyword}æ•™ç¨‹",
        ]
        
        for i in range(count):
            # éšæœºé€‰æ‹©æ ‡é¢˜æ¨¡æ¿
            title = random.choice(title_templates)
            
            # æ¨¡æ‹Ÿäº’åŠ¨æ•°æ®ï¼ˆç¬¦åˆçœŸå®åˆ†å¸ƒï¼‰
            likes = random.randint(50, 5000)
            collects = int(likes * random.uniform(0.3, 0.8))
            comments = int(likes * random.uniform(0.05, 0.2))
            
            # æ¨¡æ‹Ÿå‘å¸ƒæ—¶é—´ï¼ˆæœ€è¿‘7å¤©ï¼‰
            days_ago = random.randint(0, 7)
            publish_time = (datetime.now() - timedelta(days=days_ago)).isoformat()
            
            mock_note = {
                'id': f'mock_{int(datetime.now().timestamp())}_{i}',
                'title': title,
                'author': f'ç”¨æˆ·{random.randint(1000, 9999)}',
                'likes': likes,
                'collects': collects,
                'comments': comments,
                'publish_time': publish_time,
                'platform': platform,
                '_is_mock': True,  # æ ‡è®°ä¸º Mock æ•°æ®
                '_mock_reason': 'APIå’ŒHTMLæå–å‡å¤±è´¥ï¼Œå¯ç”¨ä¿åº•æœºåˆ¶'
            }
            
            mock_data.append(mock_note)
        
        return mock_data


# ä½¿ç”¨ç¤ºä¾‹
async def demo_extraction():
    """æ¼”ç¤ºä¸‰å±‚é™çº§æŠ“å–"""
    engine = ExtractionEngine()
    
    async def mock_api_extractor():
        """æ¨¡æ‹Ÿ API æå–"""
        # å‡è®¾ API è¢«æ‹¦æˆªï¼Œè¿”å›ç©º
        return []
    
    async def mock_html_extractor():
        """æ¨¡æ‹Ÿ HTML æå–"""
        # å‡è®¾ HTML ç»“æ„å˜åŒ–ï¼Œè¿”å›ç©º
        return []
    
    async def mock_generator(context):
        """Mock ç”Ÿæˆå™¨"""
        return await SmartMockGenerator.generate_trending_data(context)
    
    # æ‰§è¡Œä¸‰å±‚é™çº§æŠ“å–
    results = await engine.extract_with_fallback(
        api_extractor=mock_api_extractor,
        html_extractor=mock_html_extractor,
        mock_generator=mock_generator,
        context={'keyword': 'å°çº¢ä¹¦çˆ¬è™«', 'count': 5, 'platform': 'xiaohongshu'}
    )
    
    print(f"æå–ç»“æœ: {len(results)} æ¡")
    print(f"ç»Ÿè®¡ä¿¡æ¯: {engine.get_stats()}")
    return results


if __name__ == "__main__":
    import asyncio
    asyncio.run(demo_extraction())
